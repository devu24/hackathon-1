{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Rajat\\Downloads\\Hackathon 1\\Train_eP48B9k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r'C:\\Users\\Rajat\\Downloads\\Hackathon 1\\Test_jPKyvmK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL, TARGET_COL = 'id', 'term_deposit_subscribed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nTrain contains {train.shape[0]} samples and {train.shape[1]} variables')\n",
    "print(f'\\nTest contains {test.shape[0]} samples and {test.shape[1]} variables')\n",
    "\n",
    "features = [c for c in train.columns if c not in [ID_COL, TARGET_COL]]\n",
    "print(f'\\nThe dataset contains {len(features)} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[TARGET_COL].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.countplot(train[TARGET_COL])\n",
    "plt.title(\"Target Distribution\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_per_variable = 100 * (train.isnull().sum()/train.shape[0]).round(3)\n",
    "null_values_per_variable.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "cat_cols = ['job_type',\n",
    " 'marital',\n",
    " 'education',\n",
    " 'default',\n",
    " 'housing_loan',\n",
    " 'personal_loan',\n",
    " 'communication_type',\n",
    " 'month',\n",
    " 'prev_campaign_outcome']\n",
    "num_cols = [c for c in features if c not in cat_cols]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(enumerate(train[cat_cols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(train[cat_cols]):\n",
    "    train[c].value_counts()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.subplots(2, 2, figsize=(14, 22))\n",
    "for c in train[cat_cols]:\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.countplot(train[c])\n",
    "    plt.title(c, fontsize=14)\n",
    "    plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(14, 22))\n",
    "axes = [ax for axes_row in axes for ax in axes_row]\n",
    "\n",
    "for i, c in enumerate(train[cat_cols]):\n",
    "    train[c].value_counts()[::-1].plot(kind = 'pie', ax=axes[i], autopct='%.0f', title=c, fontsize=12)\n",
    "    axes[i].set_ylabel('')    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16, 16))\n",
    "axes = [ax for axes_row in axes for ax in axes_row]\n",
    "\n",
    "for i, c in enumerate(train[cat_cols]):\n",
    "    train[c].value_counts()[::-1].plot(kind = 'barh', ax=axes[i], title=c, fontsize=14)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['term_deposit_subscribed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 2, figsize=(16, 24))\n",
    "axes = [ax for axes_row in axes for ax in axes_row]\n",
    "\n",
    "for i, c in enumerate(train[cat_cols]):\n",
    "    fltr = train[TARGET_COL] == 0\n",
    "    vc_a = train[fltr][c].value_counts(normalize=True).reset_index().rename({'index' : c, c: 'count'}, axis=1)\n",
    "    vc_b = train[~fltr][c].value_counts(normalize=True).reset_index().rename({'index' : c, c: 'count'}, axis=1)\n",
    "    vc_a[TARGET_COL] = 0\n",
    "    vc_b[TARGET_COL] = 1\n",
    "    df = pd.concat([vc_a, vc_b]).reset_index(drop = True)\n",
    "    sns.barplot(y = c, x = 'count', data =df , hue=TARGET_COL, ax=axes[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16, 24))\n",
    "axes = [ax for axes_row in axes for ax in axes_row]\n",
    "\n",
    "for i, c in enumerate(train[cat_cols]):\n",
    "    fltr = train[TARGET_COL] == 0\n",
    "    vc_a = train[fltr][c].value_counts(normalize=True).reset_index().rename({'index' : c, c: 'count'}, axis=1)\n",
    "    vc_b = train[~fltr][c].value_counts(normalize=True).reset_index().rename({'index' : c, c: 'count'}, axis=1)\n",
    "    vc_a[TARGET_COL] = 0\n",
    "    vc_b[TARGET_COL] = 1\n",
    "    df = pd.concat([vc_a, vc_b]).reset_index(drop = True)\n",
    "    sns.barplot(y = c, x = 'count', data =df , hue=TARGET_COL, ax=axes[i])\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('marital')[TARGET_COL].mean().sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7, 1, figsize=(8, 20))\n",
    "for i, c in enumerate(num_cols):\n",
    "    train[[c]].boxplot(ax=axes[i], vert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.3)\n",
    "fig, axes = plt.subplots(4, 2, figsize=(18, 14))\n",
    "axes = [ax for axes_row in axes for ax in axes_row]\n",
    "for i, c in enumerate(num_cols):\n",
    "    plot = train.groupby(TARGET_COL)[c].median().plot(kind = 'barh', title=f'Median_{c}', ax=axes[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(TARGET_COL)['balance'].median().plot(kind = 'barh', title=f'Median_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(TARGET_COL)['last_contact_duration'].median().plot(kind = 'barh', title=f'Median_last_contact_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_old'] = True\n",
    "train.loc[train['customer_age'] <= 50, 'is_old'] = False\n",
    "\n",
    "train.groupby('is_old')[TARGET_COL].mean().sort_values().plot(kind = 'barh', title='Probability of subscribing to a term deposit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(train[num_cols].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_preds(preds_test, file_name = r'C:\\Users\\Rajat\\Downloads\\Hackathon 1\\hacklive_sub.csv'):\n",
    "\n",
    "  ## 1. Setting the target column with our obtained predictions\n",
    "  ss[TARGET_COL] = preds_test\n",
    "\n",
    "  ## 2. Saving our predictions to a csv file\n",
    "\n",
    "  ss.to_csv(file_name, index = False)\n",
    "\n",
    "  ## 3. Downloading and submitting the csv file\n",
    "  #from google.colab import files\n",
    "  #files.download(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train[TARGET_COL]\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_target = np.zeros(len(train))\n",
    "\n",
    "accuracy = accuracy_score(target, preds_target)\n",
    "f1 = f1_score(target, preds_target)\n",
    "\n",
    "print(f'Accuracy score is: {accuracy}')\n",
    "print(f'F1 score is: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = np.zeros(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_preds(preds_test, file_name = 'haklive_zero_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train[['job_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0).reset_index(drop = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(-999)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc, test_proc = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop = True)\n",
    "features = [c for c in train_proc.columns if c not in [ID_COL, TARGET_COL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train_proc, test_size=0.2, random_state = 1, stratify = train_proc[TARGET_COL])\n",
    "\n",
    "###### Input to our model will be the features\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "###### Output of our model will be the TARGET_COL\n",
    "y_trn, y_val = trn[TARGET_COL], val[TARGET_COL]\n",
    "\n",
    "##### Features for the test data that we will be predicting\n",
    "X_test = test_proc[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_trn)\n",
    "\n",
    "X_trn = scaler.transform(X_trn)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state = 1)\n",
    "clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "f1_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 1)\n",
    "clf.fit(X_trn, y_trn)\n",
    "\n",
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "f1_score(y_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
